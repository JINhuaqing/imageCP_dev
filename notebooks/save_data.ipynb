{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1416230-327e-4354-81eb-1a96a5450865",
   "metadata": {},
   "source": [
    "This notebook is to save the inference data, \n",
    "\n",
    "i.e., f(x) and g(x)\n",
    "\n",
    "Note that they rely on the transformer param and evaluate date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e77e2ef3-a8d9-449c-ac20-d4c365287c68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T19:51:10.640834Z",
     "iopub.status.busy": "2024-05-17T19:51:10.640235Z",
     "iopub.status.idle": "2024-05-17T19:51:11.074599Z",
     "shell.execute_reply": "2024-05-17T19:51:11.073100Z",
     "shell.execute_reply.started": "2024-05-17T19:51:10.640786Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./mypkg\")\n",
    "from constants import RES_ROOT, FIG_ROOT, DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a14c333-3d44-41f6-8372-dfc3a36b7950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T19:51:12.973245Z",
     "iopub.status.busy": "2024-05-17T19:51:12.972694Z",
     "iopub.status.idle": "2024-05-17T19:51:13.011596Z",
     "shell.execute_reply": "2024-05-17T19:51:13.010502Z",
     "shell.execute_reply.started": "2024-05-17T19:51:12.973201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# 0,1, 2, 3, be careful about the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "80996f82-3c21-4e4c-b6b0-07444b61d6fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T19:51:13.486485Z",
     "iopub.status.busy": "2024-05-17T19:51:13.485973Z",
     "iopub.status.idle": "2024-05-17T19:51:19.002324Z",
     "shell.execute_reply": "2024-05-17T19:51:19.000654Z",
     "shell.execute_reply.started": "2024-05-17T19:51:13.486444Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "from easydict import EasyDict as edict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from numbers import Number \n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from utils.fastmri import get_dataset, run_varnet_model, load_model\n",
    "from utils.misc import save_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4d228b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_namev(v):\n",
    "    if isinstance(v, Number):\n",
    "        return f\"{v*100:.0f}\"\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "85c9cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = edict()\n",
    "config.data_root = DATA_ROOT/\"brain/multicoil_val\"\n",
    "\n",
    "config.mask_params = edict()\n",
    "config.mask_params.mask_type = 'equispaced'\n",
    "config.mask_params.center_fraction = 0.04\n",
    "config.mask_params.acceleration = 4\n",
    "\n",
    "\n",
    "config.save_fold = DATA_ROOT/(f\"{config.data_root.stem}_\"+\"_\".join([f\"{k}-{_get_namev(v)}\" for k, v in config.mask_params.items()]))\n",
    "if not config.save_fold.exists():\n",
    "    config.save_fold.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63173e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                               | 6/7270 [21:45:43<26346:34:41, 13057.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 7270 samples in the dataset.\n"
     ]
    }
   ],
   "source": [
    "fmodel = load_model(is_Ysq=False);\n",
    "gmodel = load_model(is_Ysq=True);\n",
    "\n",
    "dataset = get_dataset(\n",
    "    data_path=config.data_root, \n",
    "    mask_type=config.mask_params.mask_type, \n",
    "    center_fraction=config.mask_params.center_fraction, \n",
    "    acceleration=config.mask_params.acceleration)\n",
    "\n",
    "print(f\"There is {len(dataset)} samples in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f327401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmri.data.subsample import create_mask_for_mask_type\n",
    "from fastmri.data import SliceDataset\n",
    "import fastmri.data.transforms as T\n",
    "def get_dataset1(data_path, \n",
    "                mask_type=\"equispaced\", \n",
    "                center_fraction=0.04, \n",
    "                acceleration=4, \n",
    "                filter=None):\n",
    "    \"\"\"Get the dataset from the given file path, mask type, center fractions and accelerations.\n",
    "    Note that the input should be compatible with model training.\n",
    "    - args: \n",
    "        - data_path (str): the path to the data\n",
    "            - path to h5 files directory\n",
    "        - mask_type (str): the type of mask to use, \"equispaced\" or \"random\"\n",
    "            - we use \"equispaced\" for training the brain data\n",
    "        - center_fraction (int): the center fraction to use\n",
    "            - we use [0.04, 0.08] for training the brain data\n",
    "        - acceleration (float): the acceleration to use\n",
    "            - we use [4, 8] for training the brain data\n",
    "    - returns: \n",
    "        - dataset (SliceDataset): the dataset to use for training\n",
    "            it is a SliceDataset object, you can get data by calling dataset[i]\n",
    "    \"\"\"\n",
    "    assert mask_type in [\"equispaced\", \"random\"], \"mask_type should be either 'equispaced' or 'random'\"\n",
    "    assert center_fraction in [0.04, 0.08], \"center_fraction should be either 0.04 or 0.08\"\n",
    "    assert acceleration in [4, 8], \"acceleration should be either 4 or 8\"\n",
    "\n",
    "    mask = create_mask_for_mask_type(\n",
    "            mask_type_str=mask_type, \n",
    "            center_fractions = [center_fraction], \n",
    "            accelerations = [acceleration]\n",
    "        )\n",
    "    data_transform = T.VarNetDataTransform(mask_func=mask)\n",
    "    dataset = SliceDataset(\n",
    "            root=data_path, \n",
    "            transform=data_transform, \n",
    "            challenge=\"multicoil\", \n",
    "            sample_rate=None, \n",
    "            raw_sample_filter=filter\n",
    "        )\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def run_varnet_model(batch, \n",
    "                     model, \n",
    "                     is_Ysq = False):\n",
    "    \"\"\"\n",
    "    get the output of the model\n",
    "    - args: \n",
    "        - batch: the batch of data\n",
    "            get it from data loader\n",
    "        - model: the trianed model\n",
    "        - is_Ysq: if the model trained for Y^2 or not \n",
    "            - if True, the model will output Y^2\n",
    "    - return:\n",
    "        - output: the output of the model\n",
    "    \"\"\"\n",
    "    mask = batch.mask\n",
    "    masked_kspace = batch.masked_kspace\n",
    "    crop_size = batch.crop_size\n",
    "    if batch.mask.dim() == 4:\n",
    "        mask = mask[None]\n",
    "        masked_kspace = masked_kspace[None]\n",
    "    else:\n",
    "        assert batch.mask.shape[0], \"currently only support batch size 1\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(masked_kspace, mask).cpu()\n",
    "    return output.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7a573dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 492 samples in the dataset.\n",
      "There is 518 samples in the dataset.\n"
     ]
    }
   ],
   "source": [
    "dataset1 = get_dataset1(\n",
    "    data_path=config.data_root, \n",
    "    mask_type=config.mask_params.mask_type, \n",
    "    center_fraction=config.mask_params.center_fraction, \n",
    "    acceleration=config.mask_params.acceleration, \n",
    "    filter=lambda x: x.fname.stem.split(\"_\")[2]==\"AXT1\")\n",
    "dataset2 = get_dataset1(\n",
    "    data_path=config.data_root, \n",
    "    mask_type=config.mask_params.mask_type, \n",
    "    center_fraction=config.mask_params.center_fraction, \n",
    "    acceleration=config.mask_params.acceleration, \n",
    "    filter=lambda x: x.fname.stem.split(\"_\")[2]==\"AXFLAIR\")\n",
    "\n",
    "print(f\"There is {len(dataset1)} samples in the dataset.\")\n",
    "print(f\"There is {len(dataset2)} samples in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8301c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = dataset1[1];\n",
    "batch2 = dataset2[380];\n",
    "\n",
    "res1 = run_varnet_model(batch1, fmodel);\n",
    "res2 = run_varnet_model(batch2, fmodel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d29024c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([16, 640, 320, 2])\n",
      "1 torch.Size([16, 640, 320, 2])\n",
      "2 torch.Size([16, 640, 320, 2])\n",
      "3 torch.Size([16, 640, 320, 2])\n",
      "4 torch.Size([16, 640, 320, 2])\n",
      "5 torch.Size([16, 640, 320, 2])\n",
      "6 torch.Size([16, 640, 320, 2])\n",
      "7 torch.Size([16, 640, 320, 2])\n",
      "8 torch.Size([16, 640, 320, 2])\n",
      "9 torch.Size([16, 640, 320, 2])\n",
      "10 torch.Size([16, 640, 320, 2])\n",
      "11 torch.Size([16, 640, 320, 2])\n",
      "12 torch.Size([16, 640, 320, 2])\n",
      "13 torch.Size([16, 640, 320, 2])\n",
      "14 torch.Size([16, 640, 320, 2])\n",
      "15 torch.Size([16, 640, 320, 2])\n",
      "16 torch.Size([20, 640, 320, 2])\n",
      "17 torch.Size([20, 640, 320, 2])\n",
      "18 torch.Size([20, 640, 320, 2])\n",
      "19 torch.Size([20, 640, 320, 2])\n",
      "20 torch.Size([20, 640, 320, 2])\n",
      "21 torch.Size([20, 640, 320, 2])\n",
      "22 torch.Size([20, 640, 320, 2])\n",
      "23 torch.Size([20, 640, 320, 2])\n",
      "24 torch.Size([20, 640, 320, 2])\n",
      "25 torch.Size([20, 640, 320, 2])\n",
      "26 torch.Size([20, 640, 320, 2])\n",
      "27 torch.Size([20, 640, 320, 2])\n",
      "28 torch.Size([20, 640, 320, 2])\n",
      "29 torch.Size([20, 640, 320, 2])\n",
      "30 torch.Size([20, 640, 320, 2])\n",
      "31 torch.Size([20, 640, 320, 2])\n",
      "32 torch.Size([16, 640, 320, 2])\n",
      "33 torch.Size([16, 640, 320, 2])\n",
      "34 torch.Size([16, 640, 320, 2])\n",
      "35 torch.Size([16, 640, 320, 2])\n",
      "36 torch.Size([16, 640, 320, 2])\n",
      "37 torch.Size([16, 640, 320, 2])\n",
      "38 torch.Size([16, 640, 320, 2])\n",
      "39 torch.Size([16, 640, 320, 2])\n",
      "40 torch.Size([16, 640, 320, 2])\n",
      "41 torch.Size([16, 640, 320, 2])\n",
      "42 torch.Size([16, 640, 320, 2])\n",
      "43 torch.Size([16, 640, 320, 2])\n",
      "44 torch.Size([16, 640, 320, 2])\n",
      "45 torch.Size([16, 640, 320, 2])\n",
      "46 torch.Size([16, 640, 320, 2])\n",
      "47 torch.Size([16, 640, 320, 2])\n",
      "48 torch.Size([20, 640, 320, 2])\n",
      "49 torch.Size([20, 640, 320, 2])\n",
      "50 torch.Size([20, 640, 320, 2])\n",
      "51 torch.Size([20, 640, 320, 2])\n",
      "52 torch.Size([20, 640, 320, 2])\n",
      "53 torch.Size([20, 640, 320, 2])\n",
      "54 torch.Size([20, 640, 320, 2])\n",
      "55 torch.Size([20, 640, 320, 2])\n",
      "56 torch.Size([20, 640, 320, 2])\n",
      "57 torch.Size([20, 640, 320, 2])\n",
      "58 torch.Size([20, 640, 320, 2])\n",
      "59 torch.Size([20, 640, 320, 2])\n",
      "60 torch.Size([20, 640, 320, 2])\n",
      "61 torch.Size([20, 640, 320, 2])\n",
      "62 torch.Size([20, 640, 320, 2])\n",
      "63 torch.Size([20, 640, 320, 2])\n",
      "64 torch.Size([20, 640, 320, 2])\n",
      "65 torch.Size([20, 640, 320, 2])\n",
      "66 torch.Size([20, 640, 320, 2])\n",
      "67 torch.Size([20, 640, 320, 2])\n",
      "68 torch.Size([20, 640, 320, 2])\n",
      "69 torch.Size([20, 640, 320, 2])\n",
      "70 torch.Size([20, 640, 320, 2])\n",
      "71 torch.Size([20, 640, 320, 2])\n",
      "72 torch.Size([20, 640, 320, 2])\n",
      "73 torch.Size([20, 640, 320, 2])\n",
      "74 torch.Size([20, 640, 320, 2])\n",
      "75 torch.Size([20, 640, 320, 2])\n",
      "76 torch.Size([20, 640, 320, 2])\n",
      "77 torch.Size([20, 640, 320, 2])\n",
      "78 torch.Size([20, 640, 320, 2])\n",
      "79 torch.Size([20, 640, 320, 2])\n",
      "80 torch.Size([20, 640, 320, 2])\n",
      "81 torch.Size([20, 640, 320, 2])\n",
      "82 torch.Size([20, 640, 320, 2])\n",
      "83 torch.Size([20, 640, 320, 2])\n",
      "84 torch.Size([20, 640, 320, 2])\n",
      "85 torch.Size([20, 640, 320, 2])\n",
      "86 torch.Size([20, 640, 320, 2])\n",
      "87 torch.Size([20, 640, 320, 2])\n",
      "88 torch.Size([20, 640, 320, 2])\n",
      "89 torch.Size([20, 640, 320, 2])\n",
      "90 torch.Size([20, 640, 320, 2])\n",
      "91 torch.Size([20, 640, 320, 2])\n",
      "92 torch.Size([20, 640, 320, 2])\n",
      "93 torch.Size([20, 640, 320, 2])\n",
      "94 torch.Size([20, 640, 320, 2])\n",
      "95 torch.Size([20, 640, 320, 2])\n",
      "96 torch.Size([20, 640, 320, 2])\n",
      "97 torch.Size([20, 640, 320, 2])\n",
      "98 torch.Size([20, 640, 320, 2])\n",
      "99 torch.Size([20, 640, 320, 2])\n",
      "100 torch.Size([20, 640, 320, 2])\n",
      "101 torch.Size([20, 640, 320, 2])\n",
      "102 torch.Size([20, 640, 320, 2])\n",
      "103 torch.Size([20, 640, 320, 2])\n",
      "104 torch.Size([20, 640, 320, 2])\n",
      "105 torch.Size([20, 640, 320, 2])\n",
      "106 torch.Size([20, 640, 320, 2])\n",
      "107 torch.Size([20, 640, 320, 2])\n",
      "108 torch.Size([20, 640, 320, 2])\n",
      "109 torch.Size([20, 640, 320, 2])\n",
      "110 torch.Size([20, 640, 320, 2])\n",
      "111 torch.Size([20, 640, 320, 2])\n",
      "112 torch.Size([20, 640, 320, 2])\n",
      "113 torch.Size([20, 640, 320, 2])\n",
      "114 torch.Size([20, 640, 320, 2])\n",
      "115 torch.Size([20, 640, 320, 2])\n",
      "116 torch.Size([20, 640, 320, 2])\n",
      "117 torch.Size([20, 640, 320, 2])\n",
      "118 torch.Size([20, 640, 320, 2])\n",
      "119 torch.Size([20, 640, 320, 2])\n",
      "120 torch.Size([20, 640, 320, 2])\n",
      "121 torch.Size([20, 640, 320, 2])\n",
      "122 torch.Size([20, 640, 320, 2])\n",
      "123 torch.Size([20, 640, 320, 2])\n",
      "124 torch.Size([20, 640, 320, 2])\n",
      "125 torch.Size([20, 640, 320, 2])\n",
      "126 torch.Size([16, 640, 320, 2])\n",
      "127 torch.Size([16, 640, 320, 2])\n",
      "128 torch.Size([16, 640, 320, 2])\n",
      "129 torch.Size([16, 640, 320, 2])\n",
      "130 torch.Size([16, 640, 320, 2])\n",
      "131 torch.Size([16, 640, 320, 2])\n",
      "132 torch.Size([16, 640, 320, 2])\n",
      "133 torch.Size([16, 640, 320, 2])\n",
      "134 torch.Size([16, 640, 320, 2])\n",
      "135 torch.Size([16, 640, 320, 2])\n",
      "136 torch.Size([16, 640, 320, 2])\n",
      "137 torch.Size([16, 640, 320, 2])\n",
      "138 torch.Size([16, 640, 320, 2])\n",
      "139 torch.Size([16, 640, 320, 2])\n",
      "140 torch.Size([16, 640, 320, 2])\n",
      "141 torch.Size([16, 640, 320, 2])\n",
      "142 torch.Size([16, 640, 320, 2])\n",
      "143 torch.Size([16, 640, 320, 2])\n",
      "144 torch.Size([16, 640, 320, 2])\n",
      "145 torch.Size([16, 640, 320, 2])\n",
      "146 torch.Size([16, 640, 320, 2])\n",
      "147 torch.Size([16, 640, 320, 2])\n",
      "148 torch.Size([16, 640, 320, 2])\n",
      "149 torch.Size([16, 640, 320, 2])\n",
      "150 torch.Size([16, 640, 320, 2])\n",
      "151 torch.Size([16, 640, 320, 2])\n",
      "152 torch.Size([16, 640, 320, 2])\n",
      "153 torch.Size([16, 640, 320, 2])\n",
      "154 torch.Size([16, 640, 320, 2])\n",
      "155 torch.Size([16, 640, 320, 2])\n",
      "156 torch.Size([16, 640, 320, 2])\n",
      "157 torch.Size([16, 640, 320, 2])\n",
      "158 torch.Size([16, 640, 320, 2])\n",
      "159 torch.Size([16, 640, 320, 2])\n",
      "160 torch.Size([16, 640, 320, 2])\n",
      "161 torch.Size([16, 640, 320, 2])\n",
      "162 torch.Size([16, 640, 320, 2])\n",
      "163 torch.Size([16, 640, 320, 2])\n",
      "164 torch.Size([16, 640, 320, 2])\n",
      "165 torch.Size([16, 640, 320, 2])\n",
      "166 torch.Size([16, 640, 320, 2])\n",
      "167 torch.Size([16, 640, 320, 2])\n",
      "168 torch.Size([16, 640, 320, 2])\n",
      "169 torch.Size([16, 640, 320, 2])\n",
      "170 torch.Size([16, 640, 320, 2])\n",
      "171 torch.Size([16, 640, 320, 2])\n",
      "172 torch.Size([16, 640, 320, 2])\n",
      "173 torch.Size([16, 640, 320, 2])\n",
      "174 torch.Size([16, 640, 320, 2])\n",
      "175 torch.Size([16, 640, 320, 2])\n",
      "176 torch.Size([16, 640, 320, 2])\n",
      "177 torch.Size([16, 640, 320, 2])\n",
      "178 torch.Size([16, 640, 320, 2])\n",
      "179 torch.Size([16, 640, 320, 2])\n",
      "180 torch.Size([16, 640, 320, 2])\n",
      "181 torch.Size([16, 640, 320, 2])\n",
      "182 torch.Size([16, 640, 320, 2])\n",
      "183 torch.Size([16, 640, 320, 2])\n",
      "184 torch.Size([16, 640, 320, 2])\n",
      "185 torch.Size([16, 640, 320, 2])\n",
      "186 torch.Size([16, 640, 320, 2])\n",
      "187 torch.Size([16, 640, 320, 2])\n",
      "188 torch.Size([16, 640, 320, 2])\n",
      "189 torch.Size([16, 640, 320, 2])\n",
      "190 torch.Size([16, 640, 320, 2])\n",
      "191 torch.Size([16, 640, 320, 2])\n",
      "192 torch.Size([16, 640, 320, 2])\n",
      "193 torch.Size([16, 640, 320, 2])\n",
      "194 torch.Size([16, 640, 320, 2])\n",
      "195 torch.Size([16, 640, 320, 2])\n",
      "196 torch.Size([16, 640, 320, 2])\n",
      "197 torch.Size([16, 640, 320, 2])\n",
      "198 torch.Size([16, 640, 320, 2])\n",
      "199 torch.Size([16, 640, 320, 2])\n",
      "200 torch.Size([16, 640, 320, 2])\n",
      "201 torch.Size([16, 640, 320, 2])\n",
      "202 torch.Size([16, 640, 320, 2])\n",
      "203 torch.Size([16, 640, 320, 2])\n",
      "204 torch.Size([16, 640, 320, 2])\n",
      "205 torch.Size([16, 640, 320, 2])\n",
      "206 torch.Size([20, 640, 320, 2])\n",
      "207 torch.Size([20, 640, 320, 2])\n",
      "208 torch.Size([20, 640, 320, 2])\n",
      "209 torch.Size([20, 640, 320, 2])\n",
      "210 torch.Size([20, 640, 320, 2])\n",
      "211 torch.Size([20, 640, 320, 2])\n",
      "212 torch.Size([20, 640, 320, 2])\n",
      "213 torch.Size([20, 640, 320, 2])\n",
      "214 torch.Size([20, 640, 320, 2])\n",
      "215 torch.Size([20, 640, 320, 2])\n",
      "216 torch.Size([20, 640, 320, 2])\n",
      "217 torch.Size([20, 640, 320, 2])\n",
      "218 torch.Size([20, 640, 320, 2])\n",
      "219 torch.Size([20, 640, 320, 2])\n",
      "220 torch.Size([20, 640, 320, 2])\n",
      "221 torch.Size([20, 640, 320, 2])\n",
      "222 torch.Size([20, 640, 320, 2])\n",
      "223 torch.Size([20, 640, 320, 2])\n",
      "224 torch.Size([20, 640, 320, 2])\n",
      "225 torch.Size([20, 640, 320, 2])\n",
      "226 torch.Size([20, 640, 320, 2])\n",
      "227 torch.Size([20, 640, 320, 2])\n",
      "228 torch.Size([20, 640, 320, 2])\n",
      "229 torch.Size([20, 640, 320, 2])\n",
      "230 torch.Size([20, 640, 320, 2])\n",
      "231 torch.Size([20, 640, 320, 2])\n",
      "232 torch.Size([20, 640, 320, 2])\n",
      "233 torch.Size([20, 640, 320, 2])\n",
      "234 torch.Size([20, 640, 320, 2])\n",
      "235 torch.Size([20, 640, 320, 2])\n",
      "236 torch.Size([16, 640, 320, 2])\n",
      "237 torch.Size([16, 640, 320, 2])\n",
      "238 torch.Size([16, 640, 320, 2])\n",
      "239 torch.Size([16, 640, 320, 2])\n",
      "240 torch.Size([16, 640, 320, 2])\n",
      "241 torch.Size([16, 640, 320, 2])\n",
      "242 torch.Size([16, 640, 320, 2])\n",
      "243 torch.Size([16, 640, 320, 2])\n",
      "244 torch.Size([16, 640, 320, 2])\n",
      "245 torch.Size([16, 640, 320, 2])\n",
      "246 torch.Size([16, 640, 320, 2])\n",
      "247 torch.Size([16, 640, 320, 2])\n",
      "248 torch.Size([16, 640, 320, 2])\n",
      "249 torch.Size([16, 640, 320, 2])\n",
      "250 torch.Size([16, 640, 320, 2])\n",
      "251 torch.Size([16, 640, 320, 2])\n",
      "252 torch.Size([20, 640, 320, 2])\n",
      "253 torch.Size([20, 640, 320, 2])\n",
      "254 torch.Size([20, 640, 320, 2])\n",
      "255 torch.Size([20, 640, 320, 2])\n",
      "256 torch.Size([20, 640, 320, 2])\n",
      "257 torch.Size([20, 640, 320, 2])\n",
      "258 torch.Size([20, 640, 320, 2])\n",
      "259 torch.Size([20, 640, 320, 2])\n",
      "260 torch.Size([20, 640, 320, 2])\n",
      "261 torch.Size([20, 640, 320, 2])\n",
      "262 torch.Size([20, 640, 320, 2])\n",
      "263 torch.Size([20, 640, 320, 2])\n",
      "264 torch.Size([20, 640, 320, 2])\n",
      "265 torch.Size([20, 640, 320, 2])\n",
      "266 torch.Size([20, 640, 320, 2])\n",
      "267 torch.Size([20, 640, 320, 2])\n",
      "268 torch.Size([20, 640, 320, 2])\n",
      "269 torch.Size([20, 640, 320, 2])\n",
      "270 torch.Size([20, 640, 320, 2])\n",
      "271 torch.Size([20, 640, 320, 2])\n",
      "272 torch.Size([20, 640, 320, 2])\n",
      "273 torch.Size([20, 640, 320, 2])\n",
      "274 torch.Size([20, 640, 320, 2])\n",
      "275 torch.Size([20, 640, 320, 2])\n",
      "276 torch.Size([20, 640, 320, 2])\n",
      "277 torch.Size([20, 640, 320, 2])\n",
      "278 torch.Size([20, 640, 320, 2])\n",
      "279 torch.Size([20, 640, 320, 2])\n",
      "280 torch.Size([20, 640, 320, 2])\n",
      "281 torch.Size([20, 640, 320, 2])\n",
      "282 torch.Size([20, 640, 320, 2])\n",
      "283 torch.Size([20, 640, 320, 2])\n",
      "284 torch.Size([20, 640, 320, 2])\n",
      "285 torch.Size([20, 640, 320, 2])\n",
      "286 torch.Size([20, 640, 320, 2])\n",
      "287 torch.Size([20, 640, 320, 2])\n",
      "288 torch.Size([20, 640, 320, 2])\n",
      "289 torch.Size([20, 640, 320, 2])\n",
      "290 torch.Size([20, 640, 320, 2])\n",
      "291 torch.Size([20, 640, 320, 2])\n",
      "292 torch.Size([20, 640, 320, 2])\n",
      "293 torch.Size([20, 640, 320, 2])\n",
      "294 torch.Size([20, 640, 320, 2])\n",
      "295 torch.Size([20, 640, 320, 2])\n",
      "296 torch.Size([20, 640, 320, 2])\n",
      "297 torch.Size([20, 640, 320, 2])\n",
      "298 torch.Size([20, 640, 320, 2])\n",
      "299 torch.Size([20, 640, 320, 2])\n",
      "300 torch.Size([16, 640, 320, 2])\n",
      "301 torch.Size([16, 640, 320, 2])\n",
      "302 torch.Size([16, 640, 320, 2])\n",
      "303 torch.Size([16, 640, 320, 2])\n",
      "304 torch.Size([16, 640, 320, 2])\n",
      "305 torch.Size([16, 640, 320, 2])\n",
      "306 torch.Size([16, 640, 320, 2])\n",
      "307 torch.Size([16, 640, 320, 2])\n",
      "308 torch.Size([16, 640, 320, 2])\n",
      "309 torch.Size([16, 640, 320, 2])\n",
      "310 torch.Size([16, 640, 320, 2])\n",
      "311 torch.Size([16, 640, 320, 2])\n",
      "312 torch.Size([16, 640, 320, 2])\n",
      "313 torch.Size([16, 640, 320, 2])\n",
      "314 torch.Size([16, 640, 320, 2])\n",
      "315 torch.Size([16, 640, 320, 2])\n",
      "316 torch.Size([16, 640, 320, 2])\n",
      "317 torch.Size([16, 640, 320, 2])\n",
      "318 torch.Size([16, 640, 320, 2])\n",
      "319 torch.Size([16, 640, 320, 2])\n",
      "320 torch.Size([16, 640, 320, 2])\n",
      "321 torch.Size([16, 640, 320, 2])\n",
      "322 torch.Size([16, 640, 320, 2])\n",
      "323 torch.Size([16, 640, 320, 2])\n",
      "324 torch.Size([16, 640, 320, 2])\n",
      "325 torch.Size([16, 640, 320, 2])\n",
      "326 torch.Size([16, 640, 320, 2])\n",
      "327 torch.Size([16, 640, 320, 2])\n",
      "328 torch.Size([16, 640, 320, 2])\n",
      "329 torch.Size([16, 640, 320, 2])\n",
      "330 torch.Size([16, 640, 320, 2])\n",
      "331 torch.Size([16, 640, 320, 2])\n",
      "332 torch.Size([16, 640, 264, 2])\n",
      "333 torch.Size([16, 640, 264, 2])\n",
      "334 torch.Size([16, 640, 264, 2])\n",
      "335 torch.Size([16, 640, 264, 2])\n",
      "336 torch.Size([16, 640, 264, 2])\n",
      "337 torch.Size([16, 640, 264, 2])\n",
      "338 torch.Size([16, 640, 264, 2])\n",
      "339 torch.Size([16, 640, 264, 2])\n",
      "340 torch.Size([16, 640, 264, 2])\n",
      "341 torch.Size([16, 640, 264, 2])\n",
      "342 torch.Size([16, 640, 264, 2])\n",
      "343 torch.Size([16, 640, 264, 2])\n",
      "344 torch.Size([16, 640, 264, 2])\n",
      "345 torch.Size([16, 640, 264, 2])\n",
      "346 torch.Size([16, 640, 264, 2])\n",
      "347 torch.Size([16, 640, 264, 2])\n",
      "348 torch.Size([16, 640, 264, 2])\n",
      "349 torch.Size([16, 640, 264, 2])\n",
      "350 torch.Size([16, 640, 264, 2])\n",
      "351 torch.Size([16, 640, 264, 2])\n",
      "352 torch.Size([16, 640, 264, 2])\n",
      "353 torch.Size([16, 640, 264, 2])\n",
      "354 torch.Size([16, 640, 264, 2])\n",
      "355 torch.Size([16, 640, 264, 2])\n",
      "356 torch.Size([16, 640, 264, 2])\n",
      "357 torch.Size([16, 640, 264, 2])\n",
      "358 torch.Size([16, 640, 264, 2])\n",
      "359 torch.Size([16, 640, 264, 2])\n",
      "360 torch.Size([16, 640, 264, 2])\n",
      "361 torch.Size([16, 640, 264, 2])\n",
      "362 torch.Size([16, 640, 264, 2])\n",
      "363 torch.Size([16, 640, 264, 2])\n",
      "364 torch.Size([16, 640, 264, 2])\n",
      "365 torch.Size([16, 640, 264, 2])\n",
      "366 torch.Size([16, 640, 264, 2])\n",
      "367 torch.Size([16, 640, 264, 2])\n",
      "368 torch.Size([16, 640, 264, 2])\n",
      "369 torch.Size([16, 640, 264, 2])\n",
      "370 torch.Size([16, 640, 264, 2])\n",
      "371 torch.Size([16, 640, 264, 2])\n",
      "372 torch.Size([16, 640, 264, 2])\n",
      "373 torch.Size([16, 640, 264, 2])\n",
      "374 torch.Size([16, 640, 264, 2])\n",
      "375 torch.Size([16, 640, 264, 2])\n",
      "376 torch.Size([16, 640, 264, 2])\n",
      "377 torch.Size([16, 640, 264, 2])\n",
      "378 torch.Size([16, 640, 264, 2])\n",
      "379 torch.Size([16, 640, 264, 2])\n",
      "380 torch.Size([4, 512, 213, 2])\n",
      "381 torch.Size([4, 512, 213, 2])\n",
      "382 torch.Size([4, 512, 213, 2])\n",
      "383 torch.Size([4, 512, 213, 2])\n",
      "384 torch.Size([4, 512, 213, 2])\n",
      "385 torch.Size([4, 512, 213, 2])\n",
      "386 torch.Size([4, 512, 213, 2])\n",
      "387 torch.Size([4, 512, 213, 2])\n",
      "388 torch.Size([4, 512, 213, 2])\n",
      "389 torch.Size([4, 512, 213, 2])\n",
      "390 torch.Size([4, 512, 213, 2])\n",
      "391 torch.Size([4, 512, 213, 2])\n",
      "392 torch.Size([4, 512, 213, 2])\n",
      "393 torch.Size([4, 512, 213, 2])\n",
      "394 torch.Size([4, 512, 213, 2])\n",
      "395 torch.Size([4, 512, 213, 2])\n",
      "396 torch.Size([4, 512, 276, 2])\n",
      "397 torch.Size([4, 512, 276, 2])\n",
      "398 torch.Size([4, 512, 276, 2])\n",
      "399 torch.Size([4, 512, 276, 2])\n",
      "400 torch.Size([4, 512, 276, 2])\n",
      "401 torch.Size([4, 512, 276, 2])\n",
      "402 torch.Size([4, 512, 276, 2])\n",
      "403 torch.Size([4, 512, 276, 2])\n",
      "404 torch.Size([4, 512, 276, 2])\n",
      "405 torch.Size([4, 512, 276, 2])\n",
      "406 torch.Size([4, 512, 276, 2])\n",
      "407 torch.Size([4, 512, 276, 2])\n",
      "408 torch.Size([4, 512, 276, 2])\n",
      "409 torch.Size([4, 512, 276, 2])\n",
      "410 torch.Size([4, 512, 276, 2])\n",
      "411 torch.Size([4, 512, 276, 2])\n",
      "412 torch.Size([4, 512, 276, 2])\n",
      "413 torch.Size([4, 512, 276, 2])\n",
      "414 torch.Size([4, 512, 276, 2])\n",
      "415 torch.Size([4, 512, 276, 2])\n",
      "416 torch.Size([4, 512, 276, 2])\n",
      "417 torch.Size([4, 512, 276, 2])\n",
      "418 torch.Size([4, 512, 276, 2])\n",
      "419 torch.Size([4, 512, 276, 2])\n",
      "420 torch.Size([4, 512, 276, 2])\n",
      "421 torch.Size([4, 512, 276, 2])\n",
      "422 torch.Size([20, 640, 320, 2])\n",
      "423 torch.Size([20, 640, 320, 2])\n",
      "424 torch.Size([20, 640, 320, 2])\n",
      "425 torch.Size([20, 640, 320, 2])\n",
      "426 torch.Size([20, 640, 320, 2])\n",
      "427 torch.Size([20, 640, 320, 2])\n",
      "428 torch.Size([20, 640, 320, 2])\n",
      "429 torch.Size([20, 640, 320, 2])\n",
      "430 torch.Size([20, 640, 320, 2])\n",
      "431 torch.Size([20, 640, 320, 2])\n",
      "432 torch.Size([20, 640, 320, 2])\n",
      "433 torch.Size([20, 640, 320, 2])\n",
      "434 torch.Size([20, 640, 320, 2])\n",
      "435 torch.Size([20, 640, 320, 2])\n",
      "436 torch.Size([20, 640, 320, 2])\n",
      "437 torch.Size([20, 640, 320, 2])\n",
      "438 torch.Size([12, 640, 320, 2])\n",
      "439 torch.Size([12, 640, 320, 2])\n",
      "440 torch.Size([12, 640, 320, 2])\n",
      "441 torch.Size([12, 640, 320, 2])\n",
      "442 torch.Size([12, 640, 320, 2])\n",
      "443 torch.Size([12, 640, 320, 2])\n",
      "444 torch.Size([12, 640, 320, 2])\n",
      "445 torch.Size([12, 640, 320, 2])\n",
      "446 torch.Size([12, 640, 320, 2])\n",
      "447 torch.Size([12, 640, 320, 2])\n",
      "448 torch.Size([12, 640, 320, 2])\n",
      "449 torch.Size([12, 640, 320, 2])\n",
      "450 torch.Size([12, 640, 320, 2])\n",
      "451 torch.Size([12, 640, 320, 2])\n",
      "452 torch.Size([12, 640, 320, 2])\n",
      "453 torch.Size([12, 640, 320, 2])\n",
      "454 torch.Size([12, 640, 320, 2])\n",
      "455 torch.Size([12, 640, 320, 2])\n",
      "456 torch.Size([12, 640, 320, 2])\n",
      "457 torch.Size([12, 640, 320, 2])\n",
      "458 torch.Size([12, 640, 320, 2])\n",
      "459 torch.Size([12, 640, 320, 2])\n",
      "460 torch.Size([12, 640, 320, 2])\n",
      "461 torch.Size([12, 640, 320, 2])\n",
      "462 torch.Size([12, 640, 320, 2])\n",
      "463 torch.Size([12, 640, 320, 2])\n",
      "464 torch.Size([12, 640, 320, 2])\n",
      "465 torch.Size([12, 640, 320, 2])\n",
      "466 torch.Size([12, 640, 320, 2])\n",
      "467 torch.Size([12, 640, 320, 2])\n",
      "468 torch.Size([12, 640, 320, 2])\n",
      "469 torch.Size([12, 640, 320, 2])\n",
      "470 torch.Size([16, 640, 320, 2])\n",
      "471 torch.Size([16, 640, 320, 2])\n",
      "472 torch.Size([16, 640, 320, 2])\n",
      "473 torch.Size([16, 640, 320, 2])\n",
      "474 torch.Size([16, 640, 320, 2])\n",
      "475 torch.Size([16, 640, 320, 2])\n",
      "476 torch.Size([16, 640, 320, 2])\n",
      "477 torch.Size([16, 640, 320, 2])\n",
      "478 torch.Size([16, 640, 320, 2])\n",
      "479 torch.Size([16, 640, 320, 2])\n",
      "480 torch.Size([16, 640, 320, 2])\n",
      "481 torch.Size([16, 640, 320, 2])\n",
      "482 torch.Size([16, 640, 320, 2])\n",
      "483 torch.Size([16, 640, 320, 2])\n",
      "484 torch.Size([16, 640, 320, 2])\n",
      "485 torch.Size([16, 640, 320, 2])\n",
      "486 torch.Size([20, 640, 320, 2])\n",
      "487 torch.Size([20, 640, 320, 2])\n",
      "488 torch.Size([20, 640, 320, 2])\n",
      "489 torch.Size([20, 640, 320, 2])\n",
      "490 torch.Size([20, 640, 320, 2])\n",
      "491 torch.Size([20, 640, 320, 2])\n",
      "492 torch.Size([20, 640, 320, 2])\n",
      "493 torch.Size([20, 640, 320, 2])\n",
      "494 torch.Size([20, 640, 320, 2])\n",
      "495 torch.Size([20, 640, 320, 2])\n",
      "496 torch.Size([20, 640, 320, 2])\n",
      "497 torch.Size([20, 640, 320, 2])\n",
      "498 torch.Size([20, 640, 320, 2])\n",
      "499 torch.Size([20, 640, 320, 2])\n",
      "500 torch.Size([20, 640, 320, 2])\n",
      "501 torch.Size([20, 640, 320, 2])\n",
      "502 torch.Size([16, 640, 320, 2])\n",
      "503 torch.Size([16, 640, 320, 2])\n",
      "504 torch.Size([16, 640, 320, 2])\n",
      "505 torch.Size([16, 640, 320, 2])\n",
      "506 torch.Size([16, 640, 320, 2])\n",
      "507 torch.Size([16, 640, 320, 2])\n",
      "508 torch.Size([16, 640, 320, 2])\n",
      "509 torch.Size([16, 640, 320, 2])\n",
      "510 torch.Size([16, 640, 320, 2])\n",
      "511 torch.Size([16, 640, 320, 2])\n",
      "512 torch.Size([16, 640, 320, 2])\n",
      "513 torch.Size([16, 640, 320, 2])\n",
      "514 torch.Size([16, 640, 320, 2])\n",
      "515 torch.Size([16, 640, 320, 2])\n",
      "516 torch.Size([16, 640, 320, 2])\n",
      "517 torch.Size([16, 640, 320, 2])\n"
     ]
    }
   ],
   "source": [
    "for ix in range(len(dataset2)):\n",
    "    batch = dataset2[ix]\n",
    "    print(ix, batch.masked_kspace.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c550476f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 213, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch2.masked_kspace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96f9198e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('masked_kspace',\n",
       " 'mask',\n",
       " 'num_low_frequencies',\n",
       " 'target',\n",
       " 'fname',\n",
       " 'slice_num',\n",
       " 'max_value',\n",
       " 'crop_size')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch2._fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "21a4ebbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([213, 213]), (512, 408))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch2.target.shape, batch2.crop_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1486ded8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 640, 320), (1, 512, 213))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.shape, res2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67018cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to /data/rajlab1/user_data/jin/MyResearch/imageCP_dev/mypkg/../data/mask_type-equispaced_center_fraction-4_acceleration-400/config.pkl\n"
     ]
    }
   ],
   "source": [
    "# save the config file \n",
    "save_pkl(config.save_fold/\"config.pkl\", config);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b89573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_fn(batch):\n",
    "    fn = batch.fname.split(\".\")[0]\n",
    "    sn = batch.slice_num\n",
    "    fn_root = config.save_fold/f\"{fn}-{sn}.pkl\"\n",
    "\n",
    "    if fn_root.exists():\n",
    "        print(f\"{fn_root} exists, skip it.\")\n",
    "        return\n",
    "\n",
    "    fields = batch._fields\n",
    "    res = edict()\n",
    "    res.fx = run_varnet_model(batch, fmodel)\n",
    "    res.gx = run_varnet_model(batch, gmodel,  is_Ysq=True);\n",
    "    res.target = batch.target.numpy();\n",
    "    res.mask = batch.mask.numpy();\n",
    "\n",
    "    res.attrs = edict()\n",
    "    for fv in fields:\n",
    "        # I do not save masked_kspace (x), as it is very large\n",
    "        if fv in [\"mask\", \"target\", \"masked_kspace\"]:\n",
    "            continue\n",
    "        v = getattr(batch, fv)\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            v = v.numpy()\n",
    "        res.attrs[fv] = v\n",
    "\n",
    "    save_pkl(fn_root, res, is_force=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f488c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                   | 0/7270 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 6/7270 [00:02<46:00,  2.63it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/jin/conda/envs/imageCP/lib/python3.9/site-packages/joblib/parallel.py:1457\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ready_batches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mEmpty:\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;66;03m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[1;32m   1460\u001b[0m     \u001b[38;5;66;03m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1463\u001b[0m     \u001b[38;5;66;03m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;66;03m# workers.\u001b[39;00m\n",
      "File \u001b[0;32m~/jin/conda/envs/imageCP/lib/python3.9/queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 168\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m n_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset)\n\u001b[1;32m      2\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jin/conda/envs/imageCP/lib/python3.9/site-packages/joblib/parallel.py:2005\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1999\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_ref \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(output)\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m-> 2005\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/jin/conda/envs/imageCP/lib/python3.9/site-packages/joblib/parallel.py:1643\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1641\u001b[0m detach_generator_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1643\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1644\u001b[0m     \u001b[38;5;66;03m# first yield returns None, for internal use only. This ensures\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m     \u001b[38;5;66;03m# that we enter the try/except block and start dispatching the\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m     \u001b[38;5;66;03m# tasks.\u001b[39;00m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m~/jin/conda/envs/imageCP/lib/python3.9/site-packages/joblib/parallel.py:1626\u001b[0m, in \u001b[0;36mParallel._start\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator, pre_dispatch):\n\u001b[1;32m   1618\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1623\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1624\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1626\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/jin/conda/envs/imageCP/lib/python3.9/site-packages/joblib/parallel.py:1469\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m   1466\u001b[0m big_batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m n_jobs\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1469\u001b[0m     islice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbig_batch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1471\u001b[0m     \u001b[38;5;66;03m# Handle the fact that the generator of task raised an\u001b[39;00m\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;66;03m# exception. As this part of the code can be executed in\u001b[39;00m\n\u001b[1;32m   1473\u001b[0m     \u001b[38;5;66;03m# a thread internal to the backend, register a task with\u001b[39;00m\n\u001b[1;32m   1474\u001b[0m     \u001b[38;5;66;03m# an error that will be raised in the user's thread.\u001b[39;00m\n\u001b[1;32m   1475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39m__context__, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1476\u001b[0m         \u001b[38;5;66;03m# Supress the cause of the exception if it is\u001b[39;00m\n\u001b[1;32m   1477\u001b[0m         \u001b[38;5;66;03m# queue.Empty to avoid cluttered traceback. Only do it\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m         \u001b[38;5;66;03m# if the __context__ is really empty to avoid messing\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m         \u001b[38;5;66;03m# with causes of the original error.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m n_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset)\n\u001b[1;32m      2\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[0;32m----> 4\u001b[0m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(delayed(_run_fn)(\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_data), total\u001b[38;5;241m=\u001b[39mn_data))\n",
      "File \u001b[0;32m~/jin/conda/envs/imageCP/lib/python3.9/site-packages/fastmri/data/mri_data.py:386\u001b[0m, in \u001b[0;36mSliceDataset.__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    383\u001b[0m fname, dataslice, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_samples[i]\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(fname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m hf:\n\u001b[0;32m--> 386\u001b[0m     kspace \u001b[38;5;241m=\u001b[39m \u001b[43mhf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkspace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataslice\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    388\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(hf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m hf \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    390\u001b[0m     target \u001b[38;5;241m=\u001b[39m hf[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecons_key][dataslice] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecons_key \u001b[38;5;129;01min\u001b[39;00m hf \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/jin/conda/envs/imageCP/lib/python3.9/site-packages/h5py/_hl/dataset.py:841\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    839\u001b[0m mspace \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(selection\u001b[38;5;241m.\u001b[39mmshape)\n\u001b[1;32m    840\u001b[0m fspace \u001b[38;5;241m=\u001b[39m selection\u001b[38;5;241m.\u001b[39mid\n\u001b[0;32m--> 841\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdxpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dxpl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;66;03m# Patch up the output for NumPy\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m ():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_data = len(dataset)\n",
    "n_jobs = 30\n",
    "\n",
    "Parallel(n_jobs=n_jobs)(delayed(_run_fn)(dataset[idx]) for idx in tqdm(range(n_data), total=n_data));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b916527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file_brain_AXFLAIR_200_6002471.h5'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef44cbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[9].slice_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25bea06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
